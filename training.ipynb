{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T14:20:09.586052Z",
     "iopub.status.busy": "2025-03-19T14:20:09.585763Z",
     "iopub.status.idle": "2025-03-19T14:20:21.964368Z",
     "shell.execute_reply": "2025-03-19T14:20:21.963339Z",
     "shell.execute_reply.started": "2025-03-19T14:20:09.586026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "def is_kaggle():\n",
    "    return 'KAGGLE_KERNEL_RUN_TYPE' in os.environ\n",
    "\n",
    "# Usage\n",
    "if is_kaggle():\n",
    "    print(\"Running on Kaggle\")\n",
    "    sys.path.append('/kaggle/input/urex-helperscripts')\n",
    "    sys.path.append('/kaggle/input/pop909-midis')\n",
    "    !pip install pretty_midi\n",
    "    !pip install miditok\n",
    "else:\n",
    "    print(\"Not running on Kaggle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-19T14:20:21.965949Z",
     "iopub.status.busy": "2025-03-19T14:20:21.965641Z",
     "iopub.status.idle": "2025-03-19T14:20:27.509784Z",
     "shell.execute_reply": "2025-03-19T14:20:27.509128Z",
     "shell.execute_reply.started": "2025-03-19T14:20:21.965920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch  # Ensure PyTorch is imported\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "from miditok import REMI\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "\n",
    "from vae import BetaVAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T14:20:27.512106Z",
     "iopub.status.busy": "2025-03-19T14:20:27.511643Z",
     "iopub.status.idle": "2025-03-19T14:20:27.516983Z",
     "shell.execute_reply": "2025-03-19T14:20:27.516350Z",
     "shell.execute_reply.started": "2025-03-19T14:20:27.512070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# aux fns\n",
    "\n",
    "def midi_data_loader(folder, shuffle=True):\n",
    "    tokenizer = REMI()  # using defaults parameters\n",
    "    midi_paths = [path.resolve() for path in Path(folder).rglob(\"*.mid\")][:10] # to limit files actually used, for testing purposes\n",
    "\n",
    "    dataset = DatasetMIDI(\n",
    "        files_paths=midi_paths,\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_len=1024,\n",
    "        bos_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer[\"BOS_None\"],\n",
    "    )\n",
    "    collator = DataCollator(tokenizer.pad_token_id)\n",
    "    data_loader = DataLoader(dataset=dataset, collate_fn=collator, batch_size=32, shuffle=shuffle)\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Pad sequences to the same length\n",
    "    batch = pad_sequence(batch, batch_first=True, padding_value=0)\n",
    "    # Add a feature dimension\n",
    "    batch = batch.unsqueeze(-1)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T14:20:27.518221Z",
     "iopub.status.busy": "2025-03-19T14:20:27.517961Z",
     "iopub.status.idle": "2025-03-19T14:21:33.767465Z",
     "shell.execute_reply": "2025-03-19T14:21:33.766773Z",
     "shell.execute_reply.started": "2025-03-19T14:20:27.518195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "input_dim = 128           # Each time step has 128 features (piano roll)\n",
    "hidden_dim = 256          # GRU hidden dimension\n",
    "latent_dim = 64           # Size of the latent space\n",
    "beta = 4.0                # Adjust beta for stronger disentanglement\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "model = BetaVAE(input_dim, hidden_dim, latent_dim, beta=beta)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_data_dir = \"dataset_train\"\n",
    "test_data_dir = \"dataset_test\"\n",
    "\n",
    "if is_kaggle():\n",
    "    train_data_dir = \"/kaggle/input/pop909-midis/\" + train_data_dir\n",
    "    test_data_dir = \"/kaggle/input/pop909-midis/\" + test_data_dir\n",
    "\n",
    "train_data_loader = midi_data_loader(train_data_dir, shuffle=True)\n",
    "test_data_loader = midi_data_loader(test_data_dir, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T14:21:33.768754Z",
     "iopub.status.busy": "2025-03-19T14:21:33.768298Z",
     "iopub.status.idle": "2025-03-19T14:21:34.237376Z",
     "shell.execute_reply": "2025-03-19T14:21:34.236595Z",
     "shell.execute_reply.started": "2025-03-19T14:21:33.768724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T14:21:34.238372Z",
     "iopub.status.busy": "2025-03-19T14:21:34.238125Z",
     "iopub.status.idle": "2025-03-19T14:21:34.247916Z",
     "shell.execute_reply": "2025-03-19T14:21:34.247163Z",
     "shell.execute_reply.started": "2025-03-19T14:21:34.238352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create an embedding layer (vocab_size depends on your tokenizer)\n",
    "vocab_size = len(train_data_loader.dataset.tokenizer.vocab)\n",
    "embedding_layer = nn.Embedding(vocab_size, input_dim).to(device)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T14:21:34.248812Z",
     "iopub.status.busy": "2025-03-19T14:21:34.248629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# main training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch in tqdm(train_data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        tokens = batch[\"input_ids\"].to(device)\n",
    "        embedded = embedding_layer(tokens.long())  # shape: (batch, seq_len, input_dim)\n",
    "        \n",
    "        # Forward pass through VAE\n",
    "        recon_x, mu, logvar = model(embedded.float())\n",
    "        \n",
    "        # Compute loss\n",
    "        loss, _, _ = model.loss_function(recon_x, embedded.float(), mu, logvar)\n",
    "        \n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_data_loader)\n",
    "    print(f\"Average training loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_test_loss = 0.\n",
    "    for batch in test_data_loader:\n",
    "        tokens = batch[\"input_ids\"].to(device)\n",
    "        embedded = embedding_layer(tokens.long())  # (batch, seq_len, input_dim)\n",
    "\n",
    "        recon_x, mu, logvar = model(embedded.float())\n",
    "        loss, _, _ = model.loss_function(recon_x, embedded.float(), mu, logvar)\n",
    "        total_test_loss += loss.item()\n",
    "        \n",
    "    avg_test_loss = total_test_loss / len(test_data_loader)\n",
    "    print(f\"Average test loss: {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Example function to generate from an existing tokenized MIDI file\n",
    "def generate_from_token_file(test_midi_file_path, test_output_file_path):\n",
    "    # Create a small dataset/loader from the single file\n",
    "    tokenizer = REMI()\n",
    "    single_dataset = DatasetMIDI(\n",
    "        files_paths=[Path(test_midi_file_path)],\n",
    "        tokenizer=tokenizer,\n",
    "        max_seq_len=1024,\n",
    "        bos_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer[\"BOS_None\"],\n",
    "    )\n",
    "    collator = DataCollator(tokenizer.pad_token_id)\n",
    "    single_loader = DataLoader(single_dataset, batch_size=1, shuffle=False, collate_fn=collator)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(single_loader))\n",
    "        tokens = batch[\"input_ids\"].to(device)  # shape: (1, seq_len)\n",
    "        \n",
    "        # Embed tokens\n",
    "        embedded = embedding_layer(tokens.long())  # shape: (1, seq_len, input_dim)\n",
    "        \n",
    "        # Encode to latent\n",
    "        mu, logvar = model.encode(embedded.float())\n",
    "        z = model.reparameterize(mu, logvar)\n",
    "        \n",
    "        # Decode back to feature vectors\n",
    "        decoded = model.decode(z, seq_len=256)  # pick a sequence length\n",
    "        predicted_tokens = torch.argmax(decoded, dim=-1)  # shape: (1, seq_len)\n",
    "\n",
    "        # convert predicted tokens to a plain Python list, so that __ids_to_tokens can read it\n",
    "        predicted_tokens = predicted_tokens.squeeze().tolist()\n",
    "        \n",
    "        # Convert integers to token strings\n",
    "        token_strings = tokenizer._ids_to_tokens(predicted_tokens)\n",
    "        # Convert token strings back to MIDI\n",
    "        generated_midi = tokenizer([token_strings])\n",
    "        # print(len(tokens))\n",
    "        generated_midi.dump_midi(Path(test_output_file_path))\n",
    "\n",
    "if is_kaggle():\n",
    "    test_midi_file_path = \"/kaggle/input/pop909-midis/dataset_valid/001_t0_0.mid\"\n",
    "    test_output_file_path = \"/kaggle/working/trained_decoded_estimate.mid\"\n",
    "else:\n",
    "    test_midi_file_path = \"dataset_valid/001_t0_0.mid\"\n",
    "    test_output_file_path = \"trained_decoded_estimate.mid\"\n",
    "\n",
    "generate_from_token_file(test_midi_file_path, test_output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6813299,
     "sourceId": 11089335,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6813208,
     "sourceId": 11089801,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
